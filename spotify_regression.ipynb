{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Kernel) Ridge Regression\n",
    "Download the Spotify Tracks Dataset and perform ridge regression to predict the tracksâ€™ popularity. Note that this dataset contains both numerical and categorical features. The student is thus required to follow these guidelines:\n",
    "- first, train the model using only the numerical features,\n",
    "- second, appropriately handle the categorical features (for example, with one-hot encoding or other techniques) and use them together with the numerical ones to train the model, in both cases, experiment with different training parameters, \n",
    "- use 5-fold cross validation to compute your risk estimates, thoroughly discuss and compare the performance of the model\n",
    "\n",
    "The student is required to implement from scratch (without using libraries, such as Scikit-learn) the code for the ridge regression, while it is not mandatory to do so for the implementation of the 5-fold cross-validation.\n",
    "\n",
    "Optional: Instead of regular ridge regression, implement kernel ridge regression using a Gaussian kernel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODOS\n",
    " - for each alpha, save the computed loss in order to draw a graph \n",
    " - try to avoid some features for seeing whether or not the loss decreases\n",
    " - compare our cv with the skitlearn cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the dataset\n",
    "\n",
    "dataset = \"data/dataset.csv\"\n",
    "\n",
    "dataset_df = pd.read_csv(dataset).drop(columns='Unnamed: 0')\n",
    "dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training set and test set\n",
    "\n",
    "np.random.seed(0)\n",
    "mask = np.random.rand(len(dataset_df))<0.7\n",
    "\n",
    "train_df = dataset_df[mask]\n",
    "test_set = dataset_df[~mask]\n",
    "\n",
    "# y_train_df = train_df[[\"popularity\"]]\n",
    "# y_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features\n",
    "numerical_df = dataset_df[[\"popularity\", \"duration_ms\", \"danceability\", \"energy\", \"loudness\", \"speechiness\", \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\"]]\n",
    "\n",
    "train_num_df = numerical_df[mask]\n",
    "test_num_df = numerical_df[~mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features\n",
    "# One-hot encoding the categorical features using get_dummies\n",
    "categorical_df = pd.get_dummies(dataset_df.drop(columns= [\"track_id\", \"artists\", \"album_name\", \"track_name\"]), \n",
    "                                columns = ['explicit','key', 'mode', 'time_signature', 'track_genre'], dtype=int)\n",
    "\n",
    "train_cat_df = categorical_df[mask]\n",
    "test_cat_df = categorical_df[~mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the hyperplane using regular ridge regression\n",
    "def ridge_regression(alpha, train_set):\n",
    "    y = train_set[[\"popularity\"]]\n",
    "    train_set = train_set.drop(columns='popularity')\n",
    "    n_rows, n_cols = train_set.shape  # Get the dimensions of the input matrix s\n",
    "    s_t = train_set.transpose()  # Transpose of matrix s\n",
    "    \n",
    "    # Calculate the identity matrix with the appropriate size\n",
    "    identity = np.identity(n_cols)\n",
    "    \n",
    "    # Calculate the ridge regression coefficients using matrix operations\n",
    "    w = np.linalg.inv(alpha * identity + np.dot(s_t, train_set)).dot(s_t).dot(y)\n",
    "    \n",
    "    # Convert the coefficients to a DataFrame for better presentation\n",
    "    w_df = pd.DataFrame(w, columns=[\"Values\"], index=train_set.columns)\n",
    "    \n",
    "    return w_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the popularity of a track x using an hyperplane w\n",
    "def predict(w, x):\n",
    "    return w.transpose().dot(x.drop(labels='popularity'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average square loss of the hyperplane w\n",
    "def avg_square_loss(w, test_set):\n",
    "    y = test_set[[\"popularity\"]]\n",
    "    test_set = test_set.drop(columns='popularity')\n",
    "\n",
    "    x = test_set.values  # Convert the DataFrame to a numpy array\n",
    "    # Calculate predictions for all rows at once\n",
    "    predictions = np.dot(x, w)\n",
    "   \n",
    "    squared_diff = (predictions -  y)**2\n",
    "    total_loss = np.sum(squared_diff)\n",
    "    return total_loss.values[0]/test_set.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge regression numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the hyperplane for the numercal dataset\n",
    "result_numeric = ridge_regression(0.5, train_num_df)\n",
    "result_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the first row of the training set\n",
    "predicted_y = predict(result_numeric, train_num_df.iloc[0])\n",
    "print(f\"Predicted y: \\t{predicted_y[0]}\\nReal y: \\t{train_num_df.iloc[0]['popularity']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Average square loss of the hyperplane \n",
    "print(\"Average square loss: \", avg_square_loss(result_numeric, test_num_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge regression all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the hyperplane for the numercal dataset\n",
    "result_categoric = ridge_regression(0.5, train_cat_df)\n",
    "result_categoric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the first row of the training set\n",
    "predicted_y = predict(result_categoric, train_cat_df.iloc[0])\n",
    "print(f\"Predicted y: \\t{predicted_y[0]}\\nReal y: \\t{train_cat_df.iloc[0]['popularity']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Average square loss of the hyperplane \n",
    "print(\"Average square loss: \", avg_square_loss(result_categoric, test_cat_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(k, dataset, alphas):\n",
    "\n",
    "    # Return a df from an arraty of df excepr the i-th\n",
    "    def get_set_except_i(dataset_array, i):\n",
    "        return pd.concat(dataset_array[j] for j in range(len(dataset_array)) if i!=j)\n",
    "    \n",
    "    # Split the dataset into k parts\n",
    "    dataset_array = np.array_split(dataset, k)\n",
    "    \n",
    "    losses = []\n",
    "\n",
    "    for i in range(k):\n",
    "        # In the i-th iteration, Si is the test and S\\Si is the training\n",
    "        test_cv = dataset_array[i] \n",
    "        train_cv = get_set_except_i(dataset_array, i)\n",
    "\n",
    "        # Split the training set into a new training set and a valid set\n",
    "        train_cv_array = np.array_split(train_cv, k-1)\n",
    "        dev_cv = train_cv_array[0]\n",
    "        nested_cv = get_set_except_i(train_cv_array, 0)\n",
    "        \n",
    "        # Find the best hyperparameter of your alphas\n",
    "        loss = float(\"inf\")\n",
    "        alpha = 0\n",
    "        for a in alphas:\n",
    "            predictor = ridge_regression(a, nested_cv)\n",
    "\n",
    "            local_loss = avg_square_loss(predictor, dev_cv)\n",
    "            if loss > local_loss:\n",
    "                loss = local_loss\n",
    "                alpha = a\n",
    "                \n",
    "        # Compute k predictors and their losses\n",
    "        prediction = ridge_regression(alpha, train_cv)\n",
    "        losses.append(avg_square_loss(prediction, test_cv))\n",
    "\n",
    "    #Find the avg loss of the predictors\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "alphas = 10**np.linspace(10, -2, 100)*0.5\n",
    "\n",
    "cross_validation(K, categorical_df, alphas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
