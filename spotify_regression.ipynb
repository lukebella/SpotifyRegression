{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Kernel) Ridge Regression\n",
    "Download the Spotify Tracks Dataset and perform ridge regression to predict the tracksâ€™ popularity. Note that this dataset contains both numerical and categorical features. The student is thus required to follow these guidelines:\n",
    "- first, train the model using only the numerical features,\n",
    "- second, appropriately handle the categorical features (for example, with one-hot encoding or other techniques) and use them together with the numerical ones to train the model, in both cases, experiment with different training parameters, \n",
    "- use 5-fold cross validation to compute your risk estimates, thoroughly discuss and compare the performance of the model\n",
    "\n",
    "The student is required to implement from scratch (without using libraries, such as Scikit-learn) the code for the ridge regression, while it is not mandatory to do so for the implementation of the 5-fold cross-validation.\n",
    "\n",
    "Optional: Instead of regular ridge regression, implement kernel ridge regression using a Gaussian kernel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODOS\n",
    " - CV kernel on gamma and alpha on a small number of datapoints (train and test on more datatpoints)\n",
    " - Retest and download plots (pick, except for kernel, the same sizes for train and test sets)\n",
    " - Fix markdown, comments and structure\n",
    " - Add README"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google Colab Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"google.colab\" in str(get_ipython()):\n",
    "    !git clone https://github.com/lukebella/SpotifyRegression.git\n",
    "    !mv SpotifyRegression/* .\n",
    "    !rm -fr SpotifyRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert your Kaggle credentials for downloading the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['KAGGLE_USERNAME'] = \"xxxxxx\"\n",
    "os.environ['KAGGLE_KEY'] = \"xxxxxx\"\n",
    "!kaggle datasets download -p ./data -d maharshipandya/-spotify-tracks-dataset\n",
    "!unzip -n ./data/-spotify-tracks-dataset.zip -d ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.metrics import mean_squared_error\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the dataset\n",
    "\n",
    "dataset_file = \"data/dataset.csv\"\n",
    "\n",
    "dataset_df = pd.read_csv(dataset_file).drop(columns='Unnamed: 0')\n",
    "dataset_df = dataset_df.sample(frac = 1, random_state=0).dropna()\n",
    "\n",
    "dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize loudness and tempo\n",
    "\n",
    "loudness_norm = dataset_df[\"loudness\"]\n",
    "tempo_norm = dataset_df[\"tempo\"]\n",
    "\n",
    "tempo_norm = tempo_norm/tempo_norm.max(axis=0)\n",
    "\n",
    "#(abs(min(col)) + i)/max+abs(min(col))\n",
    "\n",
    "min_loud = abs(loudness_norm.min(axis=0))\n",
    "max_loud = abs(loudness_norm.max(axis=0))\n",
    "\n",
    "loudness_norm = (min_loud+loudness_norm)/(min_loud+max_loud)\n",
    "dataset_df[\"loudness\"] = loudness_norm\n",
    "dataset_df[\"tempo\"] = tempo_norm\n",
    "\n",
    "#print(dataset_df[\"loudness\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with only track_id and track_genre one-hot encoded\n",
    "track_genre_df = pd.get_dummies(dataset_df[[\"track_id\", \"track_genre\"]], columns=['track_genre'], dtype=int)\n",
    "\n",
    "# Merge the track with the same id\n",
    "track_genre_df = track_genre_df.groupby(\"track_id\", as_index=False)[[i for i in track_genre_df.columns if i.startswith(\"track_genre_\")]].agg(np.sum)\n",
    "\n",
    "# Create a partial DataFrame with all feature except track_genre\n",
    "partial_df = pd.get_dummies(dataset_df.drop(columns=[\"artists\", \"album_name\", \"track_name\", 'track_genre']),\n",
    "                            columns=['explicit', 'key', 'mode', 'time_signature'], dtype=int) \\\n",
    "    .drop_duplicates(subset=['track_id'])\n",
    "\n",
    "# Merge partial_df and track_genre_df to create the new dataset\n",
    "categorical_df = pd.merge(partial_df, track_genre_df, on=['track_id'], how='inner').drop(columns=\"track_id\")\n",
    "\n",
    "# Removed explicit_False because haveing explicit_True this features is useless\n",
    "categorical_df = categorical_df.drop(columns=[\"explicit_False\"])\n",
    "categorical_df = categorical_df.rename(columns={\"explicit_True\": \"explicit\"})\n",
    "\n",
    "categorical_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask to split the dataset into training set and test set\n",
    "\n",
    "np.random.seed(0)\n",
    "mask = np.random.rand(len(categorical_df))<0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features\n",
    "\n",
    "train_cat_df = categorical_df[mask]\n",
    "test_cat_df = categorical_df[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features\n",
    "numerical_df = categorical_df[[\"popularity\", \"duration_ms\", \"danceability\", \"energy\", \"loudness\",\n",
    "                           \"speechiness\", \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\"]]\n",
    "\n",
    "train_num_df = numerical_df[mask]\n",
    "test_num_df = numerical_df[~mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the hyperplane using regular ridge regression\n",
    "def ridge_regression(alpha, train_set):\n",
    "    y = train_set[[\"popularity\"]]\n",
    "    train_set = train_set.drop(columns='popularity')\n",
    "    n_rows, n_cols = train_set.shape  # Get the dimensions of the input matrix s\n",
    "    s_t = train_set.transpose()  # Transpose of matrix s\n",
    "    \n",
    "    # Calculate the identity matrix with the appropriate size\n",
    "    identity = np.identity(n_cols)\n",
    "    \n",
    "    # Calculate the ridge regression coefficients using matrix operations\n",
    "    w = (np.linalg.inv(alpha * identity + np.dot(s_t, train_set)).dot(s_t)).dot(y) \n",
    "    \n",
    "    # Convert the coefficients to a DataFrame for better presentation\n",
    "    w_df = pd.DataFrame(w, columns=[\"Values\"], index=train_set.columns)\n",
    "    \n",
    "    return w_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the popularity of a track x using an hyperplane w\n",
    "def predict(w, x):\n",
    "    pred = w.transpose().dot(x.drop(labels='popularity'))[0]\n",
    "    #pred = max(0, pred)\n",
    "    #return min(100, pred)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average square loss of the hyperplane w\n",
    "def avg_square_loss(w, test_set):\n",
    "    y = test_set[[\"popularity\"]]\n",
    "    test_set = test_set.drop(columns='popularity')\n",
    "    # Convert the DataFrame to a numpy array\n",
    "    x = test_set.values  \n",
    "    # Calculate predictions for all rows at once\n",
    "    predictions = np.dot(x, w)\n",
    "    \n",
    "    squared_diff = (predictions -  y)**2\n",
    "    total_loss = np.sum(squared_diff)\n",
    "    return total_loss.values[0]/test_set.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression using only numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the hyperplane for the numercal dataset\n",
    "result_numeric = ridge_regression(0.5, train_num_df)\n",
    "result_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the first row of the training set\n",
    "predicted_y = predict(result_numeric, train_num_df.iloc[4])\n",
    "print(f\"Predicted y: \\t{predicted_y}\\nReal y: \\t{train_num_df.iloc[4]['popularity']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Average square loss of the hyperplane (numerical)\n",
    "print(\"Average square loss: \", avg_square_loss(result_numeric, test_num_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 10**np.linspace(10, -2, 100)*0.5\n",
    "\n",
    "num_train_losses = []\n",
    "num_test_losses = []\n",
    "\n",
    "for a in alphas:\n",
    "    ridge = ridge_regression(a, train_num_df)\n",
    "    num_train_losses.append(avg_square_loss(ridge, train_num_df))\n",
    "    num_test_losses.append(avg_square_loss(ridge, test_num_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('MSE on numerical features')\n",
    "plt.plot(alphas, num_train_losses, label='Training accuracy')\n",
    "plt.plot(alphas, num_test_losses, label='Testing accuracy')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikitlearn Ridge regression on numerical features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scikitlearn Ridge regression\n",
    "\n",
    "alphas = 10**np.linspace(10, -2, 100)*0.5\n",
    "\n",
    "sk_num_train_losses = []\n",
    "sk_num_test_losses = []\n",
    "\n",
    "for a in alphas:\n",
    "    clf = Ridge(alpha = a)\n",
    "    clf.fit(train_num_df.drop(columns='popularity'), train_num_df['popularity'])\n",
    "    sk_num_train_losses.append(mean_squared_error(train_num_df['popularity'], clf.predict(train_num_df.drop(columns='popularity'))))\n",
    "    sk_num_test_losses.append(mean_squared_error(test_num_df['popularity'], clf.predict(test_num_df.drop(columns='popularity'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('ScikitLearn: MSE on numerical features')\n",
    "plt.plot(alphas, sk_num_train_losses, label='Training accuracy')\n",
    "plt.plot(alphas, sk_num_test_losses, label='Testing accuracy')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression considering all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the hyperplane for the numercal dataset\n",
    "result_categoric = ridge_regression(0.005, train_cat_df)\n",
    "result_categoric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the first row of the training set\n",
    "predicted_y = predict(result_categoric, train_cat_df.iloc[0])\n",
    "print(f\"Predicted y: \\t{predicted_y}\\nReal y: \\t{train_cat_df.iloc[0]['popularity']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Average square loss of the hyperplane (categorical)\n",
    "print(\"Average square loss: \", avg_square_loss(result_categoric, test_cat_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 10**np.linspace(10, -2, 100)*0.5\n",
    "\n",
    "cat_train_losses = []\n",
    "cat_test_losses = []\n",
    "\n",
    "for a in alphas:\n",
    "    ridge = ridge_regression(a, train_cat_df)\n",
    "    cat_train_losses.append(avg_square_loss(ridge, train_cat_df))\n",
    "    cat_test_losses.append(avg_square_loss(ridge, test_cat_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('MSE on all features')\n",
    "plt.plot(alphas, cat_train_losses, label='Training accuracy')\n",
    "plt.plot(alphas, cat_test_losses, label='Testing accuracy')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ScikitLearn Ridge regression on all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scikitlearn Ridge regression\n",
    "\n",
    "alphas = 10**np.linspace(10, -2, 100)*0.5\n",
    "\n",
    "sk_cat_train_losses = []\n",
    "sk_cat_test_losses = []\n",
    "\n",
    "for a in alphas:\n",
    "    clf = Ridge(alpha = a)\n",
    "    clf.fit(train_cat_df.drop(columns='popularity'), train_cat_df['popularity'])\n",
    "    sk_cat_train_losses.append(mean_squared_error(train_cat_df['popularity'], clf.predict(train_cat_df.drop(columns='popularity'))))\n",
    "    sk_cat_test_losses.append(mean_squared_error(test_cat_df['popularity'], clf.predict(test_cat_df.drop(columns='popularity'))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('ScikitLearn: MSE on all features')\n",
    "plt.plot(alphas, sk_cat_train_losses, label='Training accuracy')\n",
    "plt.plot(alphas, sk_cat_test_losses, label='Testing accuracy')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical vs All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('MSE: numerical features vs. all features')\n",
    "plt.plot(alphas, num_train_losses, label='Num training accuracy')\n",
    "plt.plot(alphas, num_test_losses, label='Num testing accuracy')\n",
    "plt.plot(alphas, cat_train_losses, label='All training accuracy')\n",
    "plt.plot(alphas, cat_test_losses, label='All testing accuracy')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Mean squared error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('MSE: numerical features vs. all features x my vs. sk')\n",
    "plt.plot(alphas, sk_num_train_losses, label='SK Num training accuracy')\n",
    "plt.plot(alphas, sk_num_test_losses, label= 'SK Num testing accuracy')\n",
    "plt.plot(alphas, sk_cat_train_losses, label='SK All training accuracy')\n",
    "plt.plot(alphas, sk_cat_test_losses, label= 'SK All testing accuracy')\n",
    "plt.plot(alphas, num_train_losses, label='Num training accuracy')\n",
    "plt.plot(alphas, num_test_losses, label='Num testing accuracy')\n",
    "plt.plot(alphas, cat_train_losses, label='All training accuracy')\n",
    "plt.plot(alphas, cat_test_losses, label='All testing accuracy')\n",
    "plt.xscale('log')\n",
    "# plt.legend()\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Mean squared error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('MSE: numerical features my vs. sk')\n",
    "plt.plot(alphas, sk_num_train_losses, label='SK Num training accuracy')\n",
    "plt.plot(alphas, sk_num_test_losses, label= 'SK Num testing accuracy')\n",
    "# plt.plot(alphas, sk_cat_train_losses, label='SK All training accuracy')\n",
    "# plt.plot(alphas, sk_cat_test_losses, label= 'SK All testing accuracy')\n",
    "plt.plot(alphas, num_train_losses, label='Num training accuracy')\n",
    "plt.plot(alphas, num_test_losses, label='Num testing accuracy')\n",
    "# plt.plot(alphas, cat_train_losses, label='All training accuracy')\n",
    "# plt.plot(alphas, cat_test_losses, label='All testing accuracy')\n",
    "plt.xscale('log')\n",
    "# plt.legend()\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Mean squared error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('MSE: all features my vs. sk')\n",
    "# plt.plot(alphas, sk_num_train_losses, label='SK Num training accuracy')\n",
    "# plt.plot(alphas, sk_num_test_losses, label= 'SK Num testing accuracy')\n",
    "plt.plot(alphas, sk_cat_train_losses, label='SK All training accuracy')\n",
    "plt.plot(alphas, sk_cat_test_losses, label= 'SK All testing accuracy')\n",
    "# plt.plot(alphas, num_train_losses, label='Num training accuracy')\n",
    "# plt.plot(alphas, num_test_losses, label='Num testing accuracy')\n",
    "plt.plot(alphas, cat_train_losses, label='All training accuracy')\n",
    "plt.plot(alphas, cat_test_losses, label='All testing accuracy')\n",
    "plt.xscale('log')\n",
    "# plt.legend()\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Mean squared error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.suptitle('MSE on numerical features')\n",
    "fig.set_size_inches(10, 5)\n",
    "\n",
    "ax1.plot(alphas, num_train_losses, label='Training accuracy')\n",
    "ax1.plot(alphas, num_test_losses, label='Testing accuracy')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xlabel('Alpha')\n",
    "ax1.set_ylabel('Mean squared error')\n",
    "ax1.legend()\n",
    "ax1.set_title(\"Scratch\")\n",
    "\n",
    "ax2.plot(alphas, sk_num_train_losses, label='Training accuracy')\n",
    "ax2.plot(alphas, sk_num_test_losses, label='Testing accuracy')\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_xlabel('Alpha')\n",
    "ax2.set_ylabel('Mean squared error')\n",
    "ax2.legend()\n",
    "ax2.set_title(\"ScikitLearn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.suptitle('MSE on all features')\n",
    "fig.set_size_inches(10, 5)\n",
    "\n",
    "ax1.plot(alphas, cat_train_losses, label='Training accuracy')\n",
    "ax1.plot(alphas, cat_test_losses, label='Testing accuracy')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xlabel('Alpha')\n",
    "ax1.set_ylabel('Mean squared error')\n",
    "ax1.legend()\n",
    "ax1.set_title(\"Scratch\")\n",
    "\n",
    "ax2.plot(alphas, sk_cat_train_losses, label='Training accuracy')\n",
    "ax2.plot(alphas, sk_cat_test_losses, label='Testing accuracy')\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_xlabel('Alpha')\n",
    "ax2.set_ylabel('Mean squared error')\n",
    "ax2.legend()\n",
    "ax2.set_title(\"ScikitLearn\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Nested) Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(k, dataset, alphas):\n",
    "\n",
    "    # Return a df from an arraty of df excepr the i-th\n",
    "    def get_set_except_i(dataset_array, i):\n",
    "        return pd.concat(dataset_array[j] for j in range(len(dataset_array)) if i!=j)\n",
    "    \n",
    "    # Split the dataset into k parts\n",
    "    dataset_array = np.array_split(dataset, k)\n",
    "    \n",
    "    losses = []\n",
    "\n",
    "    for i in range(k):\n",
    "        # In the i-th iteration, Si is the test and S\\Si is the training\n",
    "        test_cv = dataset_array[i]\n",
    "        train_cv = get_set_except_i(dataset_array, i)\n",
    "\n",
    "        # Split the training set into a new training set and a valid set (nested CV)\n",
    "        train_cv_array = np.array_split(train_cv, k-1)\n",
    "        dev_cv = train_cv_array[0]\n",
    "        nested_cv = get_set_except_i(train_cv_array, 0)\n",
    "        \n",
    "        # Find the best hyperparameter of your alphas\n",
    "        loss = float(\"inf\")\n",
    "        alpha = 0\n",
    "        for a in alphas:\n",
    "            predictor = ridge_regression(a, nested_cv)\n",
    "\n",
    "            local_loss = avg_square_loss(predictor, dev_cv)\n",
    "            if loss > local_loss:\n",
    "                loss = local_loss\n",
    "                alpha = a\n",
    "                \n",
    "        # Compute k predictors and their losses\n",
    "        prediction = ridge_regression(alpha, train_cv)\n",
    "        losses.append(avg_square_loss(prediction, test_cv))\n",
    "\n",
    "    #Find the avg loss of the predictors\n",
    "    return np.mean(losses), prediction, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CV Ridge regression on numerical features\n",
    "\n",
    "# TODO WIP ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "alphas = 10**np.linspace(10, -2, 100)*0.5\n",
    "loss_cv, pred_cv, a_cv = cross_validation(K, categorical_df[:2000], alphas)\n",
    "print(\"Average loss with nested CV: \", loss_cv)\n",
    "print(\"Best alpha with nested CV: \", a_cv)\n",
    "\n",
    "# no shuffle\n",
    "# Average loss with nested CV:  499.37945948919185\n",
    "# Best alpha with nested CV:  201.85086292982749\n",
    "\n",
    "# shuffle\n",
    "# Average loss with nested CV:  369.03813448560055\n",
    "# Best alpha with nested CV:  0.005\n",
    "\n",
    "# shuffle + group by track_genre\n",
    "# Average loss with nested CV:  275.4156551707504\n",
    "# Best alpha with nested CV:  5.361336110051605\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ScikitLearn Ridge CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 10**np.linspace(10, -2, 100)*0.5\n",
    "\n",
    "clf = RidgeCV(alphas=alphas, cv=5)\n",
    "clf.fit(categorical_df.drop(columns='popularity'),categorical_df['popularity'])\n",
    "\n",
    "sk_loss_cv = mean_squared_error(categorical_df['popularity'][:2000], clf.predict(categorical_df.drop(columns='popularity')[:2000]))\n",
    "sk_loss_cv\n",
    "\n",
    "# no shuffle\n",
    "# 392.4801619277324\n",
    "\n",
    "# shuffle\n",
    "# 367.9301797580014\n",
    "\n",
    "# shuffle + group by track_genre\n",
    "# 273.3852050852446\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Ridge Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for calculating thorugh permutations gamma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_norm(dataset, n_samples):\n",
    "    d = dataset.sample(n = n_samples, random_state = 0).values\n",
    "    norm = 0\n",
    "    for i in range(n_samples):\n",
    "        for j in range(i,n_samples):\n",
    "            norm += (np.linalg.norm(d[i] - d[j]))**2\n",
    "    return norm/n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_gamma = avg_norm(categorical_df, 4000)\n",
    "avg_gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These kernel functions take the hyperparameter gamma as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(gamma, v1, v2):\n",
    "    norm = np.square(np.linalg.norm(v1 - v2))\n",
    "    return np.exp((norm)/-(2 * (gamma))) # maybe we need to add **2 to gamma (or **0.5 to ScikitLearn RBF)\n",
    "\n",
    "\n",
    "def kernel_ridge_regression(dataset, alpha, gamma):\n",
    "    y = dataset[\"popularity\"]\n",
    "    dataset_values = dataset.drop(columns='popularity').values\n",
    "    n_samples = dataset.shape[0]\n",
    "\n",
    "    kernel = np.zeros((n_samples, n_samples))\n",
    "    for i in range(n_samples):\n",
    "        for j in range(i, n_samples):\n",
    "            kernel[i, j] = gaussian_kernel(gamma, dataset_values[i], dataset_values[j])\n",
    "\n",
    "    # we consider half of the datapoints since it is the 'specular'\n",
    "    kernel = np.triu(kernel, 1) + kernel.transpose()\n",
    "    \n",
    "    identity = np.identity(n_samples)\n",
    "\n",
    "    #alpha is the best hyperparmeter achieved by the cv process above\n",
    "    #w = y.transpose() @ np.linalg.inv((alpha * identity + kernel)) \n",
    "    w = np.linalg.solve(alpha * identity + kernel, y)\n",
    " \n",
    "    w_df = pd.DataFrame(w, columns=['weights'])\n",
    "    return w_df\n",
    "\n",
    "\n",
    "def kernel_predict(w, dataset, x, gamma):\n",
    "    x_values = x.drop(labels='popularity').values\n",
    "    dataset_values = dataset.drop(columns='popularity').values\n",
    "    kernel_values = np.array([gaussian_kernel(gamma, x_values, x_i) for x_i in dataset_values])\n",
    "    prediction = w['weights'] @ kernel_values\n",
    "    # prediction = max(0, prediction)  # ReLU\n",
    "    # prediction = min(100, prediction)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def kernel_avg_square_loss(w, train_set, test_set, gamma):\n",
    "    y = test_set[[\"popularity\"]]\n",
    "    predictions = test_set.apply(lambda r: kernel_predict(w, train_set, r, gamma), 1)\n",
    "    squared_diff = (predictions - y.transpose())**2\n",
    "    return np.mean(squared_diff, axis=1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set = train_cat_df[:5000]\n",
    "# x = categorical_df.iloc[90]\n",
    "# gamma = 10000000\n",
    "\n",
    "\n",
    "# #1 test\n",
    "# w = kernel_ridge_regression(train_set, 1, gamma)\n",
    "\n",
    "# print(x['popularity'])\n",
    "# print(kernel_predict(w, train_set, x, gamma))\n",
    "\n",
    "# kernel_loss = kernel_avg_square_loss(w, train_set, test_cat_df[:1000], gamma)\n",
    "# print(\"AVG Square loss: \", kernel_loss)\n",
    "# print(\"AVG loss: \", kernel_loss**(1/2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Kernel only on numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test kernel on numerical features\n",
    "\n",
    "train_set = train_num_df[:2000]\n",
    "x = numerical_df.iloc[90]\n",
    "\n",
    "gamma = avg_norm(train_set, train_set.shape[0])\n",
    "w = kernel_ridge_regression(train_set, 1, gamma)\n",
    "\n",
    "print(x['popularity'])\n",
    "print(kernel_predict(w, train_set, x, gamma))\n",
    "\n",
    "kernel_loss = kernel_avg_square_loss(w, train_set, test_num_df[:500], gamma)\n",
    "print(\"AVG Square loss: \", kernel_loss)\n",
    "print(\"AVG loss: \", kernel_loss**(1/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Kernel on all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test kernel on all features\n",
    "\n",
    "train_set = train_cat_df[:6000]\n",
    "x = categorical_df.iloc[90]\n",
    "\n",
    "gamma = avg_norm(train_set, train_set.shape[0])\n",
    "w = kernel_ridge_regression(train_set, 1, gamma)\n",
    "\n",
    "print(x['popularity'])\n",
    "print(kernel_predict(w, train_set, x, gamma))\n",
    "\n",
    "kernel_loss = kernel_avg_square_loss(w, train_set, test_cat_df[:1000], gamma)\n",
    "print(\"AVG Square loss: \", kernel_loss)\n",
    "print(\"AVG loss: \", kernel_loss**(1/2))\n",
    "\n",
    "# 1000 train on all test set\n",
    "# AVG Square loss:  556.4917928496213\n",
    "# AVG loss:  23.590078271375475\n",
    "\n",
    "# 6000 train 1000 test\n",
    "# AVG Square loss:  502.54840986535186\n",
    "# AVG loss:  22.41759152686461"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ScikitLearn Kernel Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scikitlearn Kernel Ridge regression on numerical features\n",
    "\n",
    "# TODO WIP ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scikitlearn Kernel Ridge regression on all features\n",
    "\n",
    "train_set = train_cat_df[:6000]\n",
    "test_set = test_cat_df[:1000]\n",
    "\n",
    "# test with linear kernel\n",
    "clf = KernelRidge(kernel=RBF(avg_gamma), alpha=a_cv, gamma=avg_gamma)\n",
    "clf.fit(train_set.drop(columns='popularity'), train_set['popularity'])\n",
    "sk_kernel_train_loss = mean_squared_error(train_set['popularity'], clf.predict(train_set.drop(columns='popularity')))\n",
    "sk_kernel_test_loss = mean_squared_error(test_set['popularity'], clf.predict(test_set.drop(columns='popularity')))\n",
    "print(\"Train \", sk_kernel_train_loss)\n",
    "print(\"Test \", sk_kernel_test_loss)\n",
    "\n",
    "# train 6000 test 1000\n",
    "# Train  488.59196560321664\n",
    "# Test  502.69249755574214"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 10. ** np.arange(-2, 5)\n",
    "# gammas = 10. ** np.arange(0, 5)\n",
    "gammas = np.linspace(1, avg_gamma*2, 5)\n",
    "print(alphas, gammas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 5000\n",
    "\n",
    "# alphas\n",
    "# gammas\n",
    "\n",
    "# re train 20000\n",
    "# re test  4000\n",
    "\n",
    "\n",
    "def kernel_cross_validation(k, dataset, alpha, gammas):\n",
    "    # Return a df from an arraty of df excepr the i-th\n",
    "    def get_set_except_i(dataset_array, i):\n",
    "        return pd.concat(dataset_array[j] for j in range(len(dataset_array)) if i!=j)\n",
    "\n",
    "    # Split the dataset into k parts\n",
    "    dataset_array = np.array_split(dataset, k)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for i in range(k):\n",
    "        # In the i-th iteration, Si is the test and S\\Si is the training\n",
    "        test_cv = dataset_array[i]\n",
    "        train_cv = get_set_except_i(dataset_array, i)\n",
    "\n",
    "        # Split the training set into a new training set and a valid set (nested CV)\n",
    "        train_cv_array = np.array_split(train_cv, k-1)\n",
    "        dev_cv = train_cv_array[0]\n",
    "        nested_cv = get_set_except_i(train_cv_array, 0)\n",
    "\n",
    "        # Find the best hyperparameter of your alphas\n",
    "        loss = float(\"inf\")\n",
    "        gamma = 0\n",
    "        for g in gammas:\n",
    "            predictor = kernel_ridge_regression(nested_cv, alpha, g)\n",
    "\n",
    "            local_loss = kernel_avg_square_loss(predictor, nested_cv, dev_cv, g)\n",
    "            if loss > local_loss:\n",
    "                loss = local_loss\n",
    "                gamma = g\n",
    "\n",
    "        # Compute k predictors and their losses\n",
    "        prediction = kernel_ridge_regression(train_cv, alpha, gamma)\n",
    "        losses.append(kernel_avg_square_loss(prediction, train_cv, test_cv, gamma))\n",
    "\n",
    "    #Find the avg loss of the predictors\n",
    "    return np.mean(losses), prediction, gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "kcv_size = 500\n",
    "kcv_df = categorical_df.sample(kcv_size, random_state=0)\n",
    "kernel_cv_losses = []\n",
    "kernel_cv_predictor = []\n",
    "kernel_cv_gamma = []\n",
    "for a in alphas:\n",
    "    tmp = kernel_cross_validation(K, kcv_df, a, gammas)\n",
    "    kernel_cv_losses.append(tmp[0])\n",
    "    kernel_cv_predictor.append(tmp[1])\n",
    "    kernel_cv_gamma.append(tmp[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(alphas)\n",
    "print(kernel_cv_gamma)\n",
    "print(kernel_cv_losses)\n",
    "ind = kernel_cv_losses.index(min(kernel_cv_losses))\n",
    "best_alpha = alphas[ind]\n",
    "best_gamma = kernel_cv_gamma[ind]\n",
    "best_gamma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_alpha = [f'{i}' for i in alphas] \n",
    "bar_name = [str(i) for i in kernel_cv_gamma]\n",
    "bar_value = kernel_cv_losses\n",
    "bar_colors = ['tab:green', 'tab:orange', 'tab:blue', 'tab:red', 'y', 'c', 'm']\n",
    "\n",
    "bars = plt.bar(bar_alpha, bar_value, label=bar_name, color=bar_colors)\n",
    "for b in bars:\n",
    "    height = b.get_height()\n",
    "    plt.text(b.get_x() + b.get_width() / 2.0, height, f'{height:.3f}', ha='center', va='bottom')\n",
    "    plt.text(b.get_x() + b.get_width() / 2.0, height/2, f'{float(b.get_label()):.1}', ha='center', va='bottom')\n",
    "\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Alpha')\n",
    "plt.title('Hyperparameter tuning in Kernel Ridge regression')\n",
    "#plt.legend() #for report, comment this line and specify that the gamma value is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and test Kernel CV with bigger set sizes\n",
    "train_cv = train_cat_df[:6000]\n",
    "test_cv = test_cat_df[:1000]\n",
    "prediction = kernel_ridge_regression(train_cv, best_alpha, best_gamma)\n",
    "kernel_avg_square_loss(prediction, train_cv, test_cv, best_gamma)\n",
    "\n",
    "# 502.50438422998735 with 6000 and 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV vs. Kernel Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_name = ['my cv', 'sk cv', 'my kernel', 'sk kernel']\n",
    "bar_value = [loss_cv, sk_loss_cv, kernel_loss, sk_kernel_test_loss]\n",
    "bar_colors = ['tab:green', 'tab:orange', 'tab:green', 'tab:orange']\n",
    "\n",
    "bars = plt.bar(bar_name, bar_value, label=bar_name, color=bar_colors)\n",
    "for b in bars:\n",
    "    height = b.get_height()\n",
    "    plt.text(b.get_x() + b.get_width() / 2.0, height, f'{height:.4f}', ha='center', va='bottom')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('CV vs. Kernel Ridge regression')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
